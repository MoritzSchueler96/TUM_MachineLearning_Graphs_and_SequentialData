{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from utils import get_mnist_data\n",
    "from models import ConvNN\n",
    "from training_and_evaluation import evaluate_robustness_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2, part 4: Randomized smoothing certification (20 pt)\n",
    "In this notebook we compare the robustness of the classifiers from Parts 1-3 via randomized smoothing.\n",
    "\n",
    "## Your task\n",
    "Complete the missing code in the respective files, i.e. `models.py`, `training_and_evaluation.py`, `attacks.py`, and this notebook. Make sure that all the functions follow the provided specification, i.e. the output of the function exactly matches the description in the docstring. \n",
    "\n",
    "Specifically, for this part you will have to implement the following functions / classes:  \n",
    "**`training_and_evaluation.py`**:\n",
    "* `evaluate_robustness_smoothing` (20pt)\n",
    "\n",
    "## General remarks\n",
    "\n",
    "Do not add or modify any code outside of the following comment blocks, or where otherwise explicitly stated.\n",
    "``` python\n",
    "##########################################################\n",
    "# YOUR CODE HERE\n",
    "...\n",
    "##########################################################\n",
    "```\n",
    "After you fill in all the missing code, restart the kernel and re-run all the cells in the notebook.\n",
    "\n",
    "The following things are **NOT** allowed:\n",
    "- Using additional `import` statements\n",
    "- Copying / reusing code from other sources (e.g. code by other students)\n",
    "\n",
    "If you plagiarise even for a single project task, you won't be eligible for the bonus this semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "mnist_testset = get_mnist_data(train=False)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "model = ConvNN()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "num_samples_1 = int(1e3)  # reduce this to 1e2 in case it takes too long, e.g. because you don't have CUDA\n",
    "num_samples_2 = int(1e4)  # reduce this to 1e3 in case it takes too long, e.g. because you don't have CUDA\n",
    "certification_batch_size = int(5e3)  # reduce this to 5e2 if required (e.g. not enough memory)\n",
    "sigma = 1\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_types = ['standard_training', \"adversarial_training\", \"randomized_smoothing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness certification\n",
    "Here we first load the checkpoints for the base classifiers of the different training methods of Parts 1-3. Then, perform robustness certification of the smooth classifier via randomized smoothing. For this, you need to implement `evaluate_robustness_smoothing` from `training_and_evaluation.py`. Follow the docstring in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10000/10000 [07:32<00:00, 22.12it/s]\n",
      "100%|██████████| 10000/10000 [07:47<00:00, 21.38it/s]\n",
      "100%|██████████| 10000/10000 [08:26<00:00, 19.75it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for training_type in training_types:\n",
    "    model.load_state_dict(torch.load(f\"models/{training_type}.checkpoint\"))\n",
    "    certification_results = evaluate_robustness_smoothing(model, sigma, mnist_testset, num_samples_1=num_samples_1,\n",
    "                                                          num_samples_2=num_samples_2, alpha=alpha, \n",
    "                                                          certification_batch_size=certification_batch_size)\n",
    "    results[training_type] = certification_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness comparison\n",
    "Compare the robustness of the different training types. As we can see, robust training via randomized smoothing leads to the best robustness.\n",
    "\n",
    "Note that the number of certified points will be lower in case you had to reduce the number of samples for performance reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "standard_training: correct_certified 2049, avg. certifiable radius: 0.7818142620224044, avg. radius: 0.6416349648417873, avg. corr certifiable radius: 1.1656302493885478,\nadversarial_training: correct_certified 944, avg. certifiable radius: 0.46022926207128323, avg. radius: 0.3535020961969527, avg. corr certifiable radius: 0.640199294330325,\nrandomized_smoothing: correct_certified 7434, avg. certifiable radius: 0.9767335592188942, avg. radius: 0.7549173679202833, avg. corr certifiable radius: 1.0033987571195686,\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'standard_training': {'abstains': 1793,\n",
       "  'false_predictions': 6158,\n",
       "  'correct_certified': 2049,\n",
       "  'avg_radius': 1.1656302493885478,\n",
       "  'avg_radius_2': 0.7818142620224044,\n",
       "  'avg_radius_all': 0.6416349648417873},\n",
       " 'adversarial_training': {'abstains': 2319,\n",
       "  'false_predictions': 6737,\n",
       "  'correct_certified': 944,\n",
       "  'avg_radius': 0.640199294330325,\n",
       "  'avg_radius_2': 0.46022926207128323,\n",
       "  'avg_radius_all': 0.3535020961969527},\n",
       " 'randomized_smoothing': {'abstains': 2271,\n",
       "  'false_predictions': 295,\n",
       "  'correct_certified': 7434,\n",
       "  'avg_radius': 1.0033987571195686,\n",
       "  'avg_radius_2': 0.9767335592188942,\n",
       "  'avg_radius_all': 0.7549173679202833}}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "for k,v in results.items():\n",
    "    print(f\"{k}: correct_certified {v['correct_certified']}, avg. certifiable radius: {v['avg_radius']}\")\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd09e7e3b6afdde088e782cbfc21b765ef90fb650680b8bf1bbdd1b35231d4c7b4f",
   "display_name": "Python 3.7.10 64-bit ('MLGS': conda)",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "metadata": {
   "interpreter": {
    "hash": "9e7e3b6afdde088e782cbfc21b765ef90fb650680b8bf1bbdd1b35231d4c7b4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}